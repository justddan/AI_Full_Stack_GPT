{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Victory Mansions is a building with glass doors that Winston Smith enters. The hallway smells of boiled cabbage and old rag mats. It has seven flights of stairs, and the lift is usually not working. There is a large colored poster of a man\\'s face with the caption \"BIG BROTHER IS WATCHING YOU\" on one end of the hallway. Inside the flat, there is a telescreen that cannot be completely shut off, and a fruity voice reading out figures related to pig-iron production.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"./files/chapter_one.docx\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"\"\"\n",
    "            Use the following portion of a long document to see if any of the text is relevant to answer the question.\n",
    "            Return any relevant text verbatim.\n",
    "            ------\n",
    "            {context}\n",
    "        \"\"\"\n",
    "     ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    question = inputs[\"question\"]\n",
    "    return \"\\n\\n\".join(map_doc_chain.invoke({\"context\": document.page_content, \"question\": question}).content for document in documents)\n",
    "\n",
    "map_chain = {\"documents\": retriever, \"question\": RunnablePassthrough()} | RunnableLambda(map_docs)\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\", \n",
    "        \"\"\"\n",
    "            Given the folling extracted parts of a long document and a question, create a final answer.\n",
    "            If you don't know the answer just say you don't know. Don't try to make up answer.\n",
    "            ------\n",
    "            {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = {\"question\": RunnablePassthrough(), \"context\": map_chain} | final_prompt | llm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
